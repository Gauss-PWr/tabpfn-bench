{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenML dataset: **_abalone_**\n",
        "## **Description**\n",
        "Make target (age) numeric**Author**:\n",
        "**Source**: Unknown -\n",
        "**Please cite**:\n",
        "\n",
        "1. Title of Database: Abalone data\n",
        "\n",
        "2. Sources:\n",
        "\n",
        "(a) Original owners of database:\n",
        "Marine Resources Division\n",
        "Marine Research Laboratories - Taroona\n",
        "Department of Primary Industry and Fisheries, Tasmania\n",
        "GPO Box 619F, Hobart, Tasmania 7001, Australia\n",
        "(contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)\n",
        "\n",
        "(b) Donor of database:\n",
        "Sam Waugh (Sam.Waugh@cs.utas.edu.au)\n",
        "Department of Computer Science, University of Tasmania\n",
        "GPO Box 252C, Hobart, Tasmania 7001, Australia\n",
        "\n",
        "(c) Date received: December 1995\n",
        "\n",
        "3. Past Usage:\n",
        "\n",
        "Sam Waugh (1995) \"Extending and benchmarking Cascade-Correlation\", PhD\n",
        "thesis, Computer Science Department, University of Tasmania.\n",
        "\n",
        "-- Test set performance (final 1044 examples, first 3133 used for training):\n",
        "24.86% Cascade-Correlation (no hidden nodes)\n",
        "26.25% Cascade-Correlation (5 hidden nodes)\n",
        "21.5%  C4.5\n",
        "0.0%  Linear Discriminate Analysis\n",
        "3.57% k=5 Nearest Neighbour\n",
        "(Problem encoded as a classification task)\n",
        "\n",
        "-- Data set samples are highly overlapped.  Further information is required\n",
        "to separate completely using affine combinations.  Other restrictions\n",
        "to data set examined.\n",
        "\n",
        "David Clark, Zoltan Schreter, Anthony Adams \"A Quantitative Comparison of\n",
        "Dystal and Backpropagation\", submitted to the Australian Conference on\n",
        "Neural Networks (ACNN'96). Data set treated as a 3-category classification\n",
        "problem (grouping ring classes 1-8, 9 and 10, and 11 on).\n",
        "\n",
        "-- Test set performance (3133 training, 1044 testing as above):\n",
        "64%    Backprop\n",
        "55%    Dystal\n",
        "-- Previous work (Waugh, 1995) on same data set:\n",
        "61.40% Cascade-Correlation (no hidden nodes)\n",
        "65.61% Cascade-Correlation (5 hidden nodes)\n",
        "59.2%  C4.5\n",
        "32.57% Linear Discriminate Analysis\n",
        "62.46% k=5 Nearest Neighbour\n",
        "\n",
        "4. Relevant Information Paragraph:\n",
        "\n",
        "Predicting the age of abalone from physical measurements.  The age of\n",
        "abalone is determined by cutting the shell through the cone, staining it,\n",
        "and counting the number of rings through a microscope -- a boring and\n",
        "time-consuming task.  Other measurements, which are easier to obtain, are\n",
        "used to predict the age.  Further information, such as weather patterns\n",
        "and location (hence food availability) may be required to solve the problem.\n",
        "\n",
        "From the original data examples with missing values were removed (the\n",
        "majority having the predicted value missing), and the ranges of the\n",
        "continuous values have been scaled for use with an ANN (by dividing by 200).\n",
        "\n",
        "Data comes from an original (non-machine-learning) study:\n",
        "\n",
        "Warwick J Nash, Tracy L Sellers, Simon R Talbot, Andrew J Cawthorn and\n",
        "Wes B Ford (1994) \"The Population Biology of Abalone (_Haliotis_\n",
        "species) in Tasmania. I. Blacklip Abalone (_H. rubra_) from the North\n",
        "Coast and Islands of Bass Strait\", Sea Fisheries Division, Technical\n",
        "Report No. 48 (ISSN 1034-3288)\n",
        "\n",
        "5. Number of Instances: 4177\n",
        "\n",
        "6. Number of Attributes: 8\n",
        "\n",
        "7. Attribute information:\n",
        "\n",
        "Given is the attribute name, attribute type, the measurement unit and a\n",
        "brief description.  The number of rings is the value to predict: either\n",
        "as a continuous value or as a classification problem.\n",
        "\n",
        "Name\t\tData Type\tMeas.\tDescription\n",
        "----\t\t---------\t-----\t-----------\n",
        "Sex\t\tnominal\t\t\tM, F, and I (infant)\n",
        "Length\t\tcontinuous\tmm\tLongest shell measurement\n",
        "Diameter\tcontinuous\tmm\tperpendicular to length\n",
        "Height\t\tcontinuous\tmm\twith meat in shell\n",
        "Whole weight\tcontinuous\tgrams\twhole abalone\n",
        "Shucked weight\tcontinuous\tgrams\tweight of meat\n",
        "Viscera weight\tcontinuous\tgrams\tgut weight (after bleeding)\n",
        "Shell weight\tcontinuous\tgrams\tafter being dried\n",
        "Rings\t\tinteger\t\t\t+1.5 gives the age in years\n",
        "\n",
        "Statistics for numeric domains:\n",
        "\n",
        "Length\tDiam\tHeight\tWhole\tShucked\tViscera\tShell\tRings\n",
        "Min\t0.075\t0.055\t0.000\t0.002\t0.001\t0.001\t0.002\t    1\n",
        "Max\t0.815\t0.650\t1.130\t2.826\t1.488\t0.760\t1.005\t   29\n",
        "Mean\t0.524\t0.408\t0.140\t0.829\t0.359\t0.181\t0.239\t9.934\n",
        "SD\t0.120\t0.099\t0.042\t0.490\t0.222\t0.110\t0.139\t3.224\n",
        "Correl\t0.557\t0.575\t0.557\t0.540\t0.421\t0.504\t0.628\t  1.0\n",
        "\n",
        "8. Missing Attribute Values: None\n",
        "\n",
        "9. Class Distribution:\n",
        "\n",
        "Class\tExamples\n",
        "-----\t--------\n",
        "1\t1\n",
        "2\t1\n",
        "3\t15\n",
        "4\t57\n",
        "5\t115\n",
        "6\t259\n",
        "7\t391\n",
        "8\t568\n",
        "9\t689\n",
        "10\t634\n",
        "11\t487\n",
        "12\t267\n",
        "13\t203\n",
        "14\t126\n",
        "15\t103\n",
        "16\t67\n",
        "17\t58\n",
        "18\t42\n",
        "19\t32\n",
        "20\t26\n",
        "21\t14\n",
        "22\t6\n",
        "23\t9\n",
        "24\t2\n",
        "25\t1\n",
        "26\t1\n",
        "27\t2\n",
        "29\t1\n",
        "-----\t----\n",
        "Total\t4177\n",
        "\n",
        "Num Instances:     4177\n",
        "Num Attributes:    9\n",
        "Num Continuous:    8 (Int 1 / Real 7)\n",
        "Num Discrete:      1\n",
        "Missing values:    0 /  0.0%\n",
        "\n",
        "name                      type enum ints real     missing    distinct  (1)\n",
        "1 'Sex'                     Enum 100%   0%   0%     0 /  0%     3 /  0%   0%\n",
        "2 'Length'                  Real   0%   0% 100%     0 /  0%   134 /  3%   0%\n",
        "3 'Diameter'                Real   0%   0% 100%     0 /  0%   111 /  3%   0%\n",
        "4 'Height'                  Real   0%   0% 100%     0 /  0%    51 /  1%   0%\n",
        "5 'Whole weight'            Real   0%   0% 100%     0 /  0%  2429 / 58%  31%\n",
        "6 'Shucked weight'          Real   0%   0% 100%     0 /  0%  1515 / 36%  10%\n",
        "7 'Viscera weight'          Real   0%   0% 100%     0 /  0%   880 / 21%   3%\n",
        "8 'Shell weight'            Real   0%   0% 100%     0 /  0%   926 / 22%   8%\n",
        "9 'Class_Rings'             Int    0% 100%   0%     0 /  0%    28 /  1%   0%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openml\n",
        "\n",
        "dataset = openml.datasets.get_dataset(42726)\n",
        "X, y, cat_atr_mask, names = dataset.get_data(target=dataset.default_target_attribute, dataset_format='dataframe')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_atr_list = X.columns[cat_atr_mask].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X['Sex'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted(y.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import pi\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "\n",
        "encoder = OrdinalEncoder()\n",
        "cols = X.columns\n",
        "X = encoder.fit_transform(X=X)\n",
        "X = pd.DataFrame(X, columns=cols)\n",
        "\n",
        "X['Volume'] = X['Diameter'] * X['Length'] * X['Height'] * pi * 3 / 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "sns.pairplot(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = X.corr()\n",
        "\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='Blues', annot_kws={\"rotation\": 45})\n",
        "plt.xticks(rotation=45) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data is very corelated with each other.\n",
        "\n",
        "----------------\n",
        "\n",
        "## **Data Prepration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X['Sex'] = X['Sex'].map({0: 'M', 1: 'F', 2: 'I'})\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "cols = X.columns.to_list()\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    ('encoder', OneHotEncoder())\n",
        "])\n",
        "num_pipe = Pipeline([\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', cat_pipe, cat_atr_list),\n",
        "    ('num', num_pipe, [atr for atr in cols if atr not in cat_atr_list])\n",
        "])\n",
        "\n",
        "catboost_preprocessor = ColumnTransformer([\n",
        "    ('cat', 'passthrough', cat_atr_list),\n",
        "    ('num', num_pipe, [atr for atr in cols if atr not in cat_atr_list])    \n",
        "], force_int_remainder_cols=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y = LabelEncoder().fit_transform(y).astype(int)\n",
        "X_prep = preprocessor.fit_transform(X)\n",
        "names = preprocessor.get_feature_names_out(X.columns)\n",
        "X_prep = pd.DataFrame(X_prep, columns=names)\n",
        "X_prep.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_catboost = catboost_preprocessor.fit_transform(X)\n",
        "names = catboost_preprocessor.get_feature_names_out(X.columns)\n",
        "X_catboost = pd.DataFrame(X_catboost, columns=names)\n",
        "X_catboost.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-------\n",
        "\n",
        "## **Model Training**\n",
        "TabPFN is a tabular data classification model optimized for datasets with up to 10 classes. To apply TabPFN to datasets exceeding this limit, such as those with 28 classes, strategies like One-vs-Rest (OvR) and Error-Correcting Output Codes (ECOC) are employed. OvR involves training a separate binary classifier for each class, distinguishing that class from all others, resulting in 28 classifiers for 28 classes. ECOC, on the other hand, represents each class with a unique binary code and trains binary classifiers for each bit position; the number of classifiers depends on the chosen code length, which can be adjusted to balance performance and computational complexity. These methods enable TabPFN to handle multi-class classification tasks beyond its original class limit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tabpfn import TabPFNClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier, OutputCodeClassifier\n",
        "\n",
        "\n",
        "one_vs_rest = OneVsRestClassifier(TabPFNClassifier(device='cuda'))\n",
        "#ecoc = OutputCodeClassifier(TabPFNClassifier())\n",
        "xgb = XGBClassifier()\n",
        "lgbm = LGBMClassifier(verbose=-1)\n",
        "cat = CatBoostClassifier(cat_features=[feature for feature in catboost_preprocessor.get_feature_names_out(X.columns) if feature.startswith('cat')], verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_prep, y, test_size=0.2, random_state=42)\n",
        "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_catboost, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import warnings\n",
        "\n",
        "import joblib\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def measure_fit_time(model, X, y):\n",
        "    start = time.time()\n",
        "    model.fit(X, y)\n",
        "    return round(time.time() - start, 2)\n",
        "\n",
        "fit = 1\n",
        "\n",
        "models = [one_vs_rest, \n",
        "          # ecoc, \n",
        "          xgb, \n",
        "          lgbm, \n",
        "          cat]\n",
        "\n",
        "if fit == 0:\n",
        "    for model in models:\n",
        "        model = joblib.load(f'models\\\\abalone\\\\{model.__class__.__name__}_no_hyperparams.joblib')\n",
        "        print(f'{model.__class__.__name__} loaded.')\n",
        "else:\n",
        "    for model in models:\n",
        "        if model.__class__.__name__ != 'CatBoostClassifier':\n",
        "            print(f'{model.__class__.__name__} fit time: {measure_fit_time(model, X_train, y_train)}s.')\n",
        "        else:\n",
        "            print(f'{model.__class__.__name__} fit time: {measure_fit_time(model, X_train_cat, y_train_cat)}s.')\n",
        "        joblib.dump(model, f'models\\\\abalone\\\\{model.__class__.__name__}_no_hyperparams.joblib')    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import (accuracy_score,\n",
        "                                precision_score,\n",
        "                                recall_score,\n",
        "                                f1_score,\n",
        "                                roc_auc_score)\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, average='weighted')\n",
        "    rec = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
        "    return acc, prec, rec, f1, roc_auc\n",
        "\n",
        "def evaluate_models(models, X_test, y_test, X_test_cat, y_test_cat):\n",
        "    results = [\n",
        "        [model.__class__.__name__, *evaluate_model(model, X_test, y_test)] if model.__class__.__name__ != 'CatBoostClassifier'\n",
        "        else [model.__class__.__name__, *evaluate_model(model, X_test_cat, y_test_cat)]\n",
        "        for model in models\n",
        "    ]\n",
        "    return pd.DataFrame(results, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'ROC AUC'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = evaluate_models(models, X_test, y_test, X_test_cat, y_test_cat)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
